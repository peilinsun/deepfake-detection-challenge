{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DrQjMUKD1Rb3",
    "outputId": "cc0087fb-e725-48f7-a3b6-abd78e606e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ri1rZzlC1cyS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/kaggle/cnn_detection/networks')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from resnet import resnet50\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbZL-7hH1ipr"
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gop_R1zA1iIj"
   },
   "outputs": [],
   "source": [
    "image_size = 224 #299\n",
    "batch_size = 64\n",
    "epoch = 10\n",
    "n_frames = 10\n",
    "hidden_dim = 100\n",
    "\n",
    "# training batch03\n",
    "data_folder = '/content/drive/My Drive/kaggle/batch03'\n",
    "metadata_dir = glob.glob(os.path.join(data_folder, 'dfdc_train_part_47', '*.json'))[0]\n",
    "split = 0.8\n",
    "model_path = '/content/drive/My Drive/kaggle/cnn_detection'\n",
    "\n",
    "# valset from batch02\n",
    "data_folder_val = '/content/drive/My Drive/kaggle/batch02'\n",
    "metadata_dir_val = glob.glob(os.path.join(data_folder_val, 'dfdc_train_part_48', '*.json'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Siizil7e1n3L",
    "outputId": "1edb853a-89db-482c-9ce8-005467fd12a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# torch.manual_seed(123)\n",
    "device = torch.device('cuda' if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnDcr1fJ1qtb"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpWX1tV_1tFd"
   },
   "source": [
    "Load data from npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0EIPXN2g1tzp"
   },
   "outputs": [],
   "source": [
    "class VideoDatasetArray(Dataset):\n",
    "    def __init__(self, root, n_frames, transform=None, train=True):\n",
    "        \"\"\" Intialize the dataset from npy files\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the data\n",
    "            - n_frame: the number of frames for each video\n",
    "            - tranform: a custom tranform function\n",
    "            - train: dataset for training\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform['train' if train else 'val']\n",
    "        face_dir = os.path.join(self.root)\n",
    "        if train:\n",
    "            face_file = glob.glob(os.path.join(face_dir, '*.npy'))\n",
    "        else:\n",
    "            face_dir = os.path.join(self.root, 'face10train')\n",
    "            face_file = [glob.glob(os.path.join(face_dir, '*.npy'))[1]]\n",
    "\n",
    "        # Preload dataset to memory\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        print(\"\\nPreload dataset to memory...\\n\")\n",
    "        for face_batch in tqdm.tqdm(face_file, ncols=80):\n",
    "            data = np.load(face_batch, allow_pickle=True)\n",
    "            labels = data.item()['y']\n",
    "            for k in range(len(labels)):\n",
    "                target = 1 if labels[k] == \"FAKE\" else 0\n",
    "                collections = []\n",
    "                for i in range(10):\n",
    "                    image = data.item()['x' + str(i)][k].transpose()\n",
    "                    collections.append(image.copy())\n",
    "                self.images.append(collections)\n",
    "                self.labels.append(target)\n",
    "            # del data\n",
    "            \n",
    "        self.len = len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        images = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        X = []\n",
    "        if self.transform is not None:\n",
    "            for image in images:\n",
    "                # image = torch.FloatTensor(image)\n",
    "                x = Image.fromarray(image.astype(np.uint8).transpose(1,2,0))\n",
    "                X.append(self.transform(x))\n",
    "        return X, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIfMTIib1wLO"
   },
   "outputs": [],
   "source": [
    "transform = {\n",
    "        'train': transforms.Compose([\n",
    "                    # transforms.ToPILImage(),\n",
    "                    transforms.Resize(image_size),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ColorJitter(hue=0.5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ]), \n",
    "        'val': transforms.Compose([\n",
    "                    transforms.Resize(image_size),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "OkvRKXKV1xQ3",
    "outputId": "e0f37f57-7376-4d6c-973b-7542d97efab2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Load Training Set -------\n",
      "\n",
      "Preload dataset to memory...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [04:29<00:00, 17.98s/it]\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Load Val Set-------\n",
      "\n",
      "Preload dataset to memory...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:18<00:00, 18.92s/it]\n"
     ]
    }
   ],
   "source": [
    "print('\\n----- Load Training Set -------')\n",
    "trainset = VideoDatasetArray(\n",
    "    root= data_folder, \n",
    "    n_frames = n_frames,\n",
    "    transform=transform, train=True\n",
    ")\n",
    "trainset_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "print('\\n----- Load Val Set-------')\n",
    "valset = VideoDatasetArray(\n",
    "    root= data_folder_val, \n",
    "    n_frames = n_frames,\n",
    "    transform=transform, train=False\n",
    ")\n",
    "valset_loader = DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8j0bKim19Pz"
   },
   "source": [
    "## Utilities for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "An1J5RgOg-eW"
   },
   "outputs": [],
   "source": [
    "class FineTune():\n",
    "    def __init__(self, model, model_name, epoch, optimizer, filename, log_interval=10):\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.epoch = epoch\n",
    "        self.optimizer = optimizer\n",
    "        self.log_interval = log_interval\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.train_accuracy = []\n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.output_folder = '/content/drive/My Drive/kaggle/output'\n",
    "        self.filename = filename\n",
    "\n",
    "    def train(self):  # set training mode\n",
    "        loss_fn = nn.BCELoss()\n",
    "        for ep in range(self.epoch):\n",
    "            self.model.train()\n",
    "            iteration = 0\n",
    "            for batch_idx, (data, target) in enumerate(trainset_loader):\n",
    "                data = [_data.to(device) for _data in data] \n",
    "                target = target.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = loss_fn(output.squeeze(dim=1), target.type_as(output))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if iteration % self.log_interval == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        ep, batch_idx * batch_size, len(trainset_loader.dataset),\n",
    "                        100. * (batch_idx+1) / len(trainset_loader), loss.item()))\n",
    "                iteration += 1\n",
    "\n",
    "            # Evaluation for both the training set and validation set\n",
    "            self.eval(False)\n",
    "            self.eval(True)\n",
    "\n",
    "            # Save\n",
    "            history = [self.train_loss, self.train_accuracy, self.val_loss, self.val_accuracy]\n",
    "            np.save(os.path.join(self.output_folder, self.filename), history)\n",
    "            torch.save({\n",
    "                        'epoch': ep,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict()\n",
    "                        }, os.path.join(self.output_folder, self.filename+'.pt'))\n",
    "        \n",
    "        # Save loss and accuracy\n",
    "        output_file = os.path.join(self.output_folder, self.filename+'.txt')\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write('train_loss\\n')\n",
    "            for item in self.train_loss:\n",
    "                f.write('%s\\n' % item)\n",
    "            f.write('train_accuracy\\n')\n",
    "            for item in self.train_accuracy:\n",
    "                f.write('%s\\n' % item)\n",
    "            f.write('val_loss\\n')\n",
    "            for item in self.val_loss:\n",
    "                f.write('%s\\n' % item)\n",
    "            f.write('val_accuracy\\n')\n",
    "            for item in self.val_accuracy:\n",
    "                f.write('%s\\n' % item)\n",
    "\n",
    "    def eval(self, is_val=True):\n",
    "        loss_fn = nn.BCELoss(reduction=\"sum\")\n",
    "        self.model.eval()  # set evaluation mode\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        data_loader = valset_loader if is_val else trainset_loader\n",
    "        with torch.no_grad():  # set all requires_grad flags to False\n",
    "            for data, target in data_loader:\n",
    "                data = [_data.to(device) for _data in data] \n",
    "                target = target.to(device)\n",
    "                output = self.model(data)\n",
    "                loss += loss_fn(output.squeeze(dim=1), target.type_as(output)).item()\n",
    "                pred = (output > 0.5).int()\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                if is_val:\n",
    "                    # for calculating precision and recall\n",
    "                    TP += (pred * target.view_as(pred)).sum().item()\n",
    "                    TN += ((1 - pred) * (1 - target.view_as(pred))).sum().item()\n",
    "                    FP += (pred * (1 - target.view_as(pred))).sum().item()\n",
    "                    FN += ((1 - pred) * target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss /= len(data_loader.dataset)\n",
    "        accuracy = 100. * correct / len(data_loader.dataset)\n",
    "\n",
    "        if is_val:\n",
    "            # save validation loss and accuracy\n",
    "            self.val_loss.append(loss)\n",
    "            self.val_accuracy.append(accuracy)\n",
    "\n",
    "            # calculate precision, recall, and f1\n",
    "            precision = TP / (TP + FP)\n",
    "            recall = TP / (TP + FN)\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            print('Val set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}'.format(\n",
    "                loss, correct, len(data_loader.dataset),\n",
    "                accuracy, precision, recall, f1))\n",
    "        else:\n",
    "            self.train_loss.append(loss)\n",
    "            self.train_accuracy.append(accuracy)\n",
    "            print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                loss, correct, len(data_loader.dataset), accuracy))\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.train_loss, label='Training loss')\n",
    "        plt.plot(self.val_loss, label='Validation loss')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_accuracy(self):\n",
    "        plt.plot(self.train_accuracy, label='Training accuracy')\n",
    "        plt.plot(self.val_accuracy, label='Validation accuracy')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHTccrMRhCbi"
   },
   "outputs": [],
   "source": [
    "def freeze_until(net, param_name):\n",
    "    found_name = False\n",
    "    for name, params in net.named_parameters():\n",
    "        if name == param_name:\n",
    "            found_name = True\n",
    "        params.requires_grad = found_name\n",
    "    \n",
    "    fine_tuned = [k for k,v in net.named_parameters() if v.requires_grad]\n",
    "    print('Layer to fine-tune:', fine_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiKtNkMF1_wp"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet_layer = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_layer(x)\n",
    "        return x\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    '''\n",
    "    Ensemble all results from different frames and train the last layer as a classifier.\n",
    "    '''\n",
    "    def __init__(self, feature_extracter, n_frames, hidden_dim, maxpool=False):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.feature_extracter = feature_extracter\n",
    "        self.lstm = nn.LSTM(2048, hidden_dim)\n",
    "        self.maxpool = nn.MaxPool1d(n_frames)\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.mp = maxpool        \n",
    "    \n",
    "    def forward(self, images):\n",
    "        batch_size = images[0].shape[0]\n",
    "        \n",
    "        X = []\n",
    "        for x in images:\n",
    "            x = torch.squeeze(self.feature_extracter(x), dim=3)\n",
    "            x = torch.transpose(x, 1, 2)\n",
    "            X.append(x)\n",
    "        features = torch.transpose(torch.cat(X, dim=1), 0, 1)\n",
    "        output, (h, _)= self.lstm(features)  # (len, batch, hidden_dim)\n",
    "        if not self.mp:\n",
    "            x = self.classifier(h.view(batch_size, -1))\n",
    "            x = self.sigmoid(x)\n",
    "        else:\n",
    "            output = self.maxpool(output.transpose(0,2)).transpose(0,2).view(batch_size, -1)\n",
    "            x = self.classifier(output)\n",
    "            x = self.sigmoid(x)\n",
    "        return x       \n",
    "\n",
    "class GRU(nn.Module):\n",
    "    '''\n",
    "    Ensemble all results from different frames and train the last layer as a classifier.\n",
    "    '''\n",
    "    def __init__(self, feature_extracter, n_frames, hidden_dim1, hidden_dim2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.feature_extracter = feature_extracter\n",
    "        self.gru1 = nn.GRU(2048, hidden_dim1)\n",
    "        self.gru2 = nn.GRU(hidden_dim1, hidden_dim2)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.classifier = nn.Linear(hidden_dim2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        X = []\n",
    "        for x in images:\n",
    "            x = torch.squeeze(self.feature_extracter(x), dim=3)\n",
    "            x = torch.transpose(x, 1, 2)\n",
    "            X.append(x)\n",
    "        features = torch.transpose(torch.cat(X, dim=1), 0, 1)\n",
    "        output, _ = self.gru1(features)\n",
    "        output = self.drop(output)\n",
    "        _, h = self.gru2(output)\n",
    "        h = self.drop(h)\n",
    "        x = self.classifier(h)\n",
    "        x = self.sigmoid(x)\n",
    "        return x       \n",
    "\n",
    "def cnn_model():\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    pretrained_dict = resnet50.state_dict()\n",
    "    model = ResNet(resnet50)\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LvQDzFG3M0m"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "d2cf26fe0d5e4a49840c2a2e5e96d8c7",
      "001ccf84694a47d88acda0feb1c060d5",
      "b4c321fec74d449ba19c47a8494ab310",
      "5fa2428671d146b09f55a3327bd72f4a",
      "914bc8e04c334997b9d4e47198d52836",
      "25cbdbd67bc24f75a09dfa5cb7cc1c73",
      "cda31c347de54dac9db23b81329450a1",
      "1ce470e7dccb45358b6d8c580abf1cc5"
     ]
    },
    "colab_type": "code",
    "id": "4zliECoW__2J",
    "outputId": "48e50349-4c08-4b0e-f735-88e44a20a34f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf26fe0d5e4a49840c2a2e5e96d8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=102502400), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conv_model = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hgz-VMjcgfpU"
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "model = LSTM(conv_model, n_frames=n_frames, hidden_dim=50, maxpool=True)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "finetune = FineTune(model, 'lstm', epoch=150, optimizer=optimizer, filename='lstm_100_0.0001SGD', log_interval=100)\n",
    "finetune.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YyyF-Job7sC"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = LSTM(conv_model, n_frames=n_frames, hidden_dim=100, maxpool=False)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "finetune = FineTune(model, 'lstm', epoch=150, optimizer=optimizer, filename='lstm_100_0.0001SGD_noMaxPool', log_interval=100)\n",
    "finetune.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oKxczrm_2HC"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = GRU(conv_model, n_frames=n_frames, hidden_dim1=50, hidden_dim2=10)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcAwp9Du-C3V"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGwFhqenB9Ju"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_extracter, n_frames, hidden_size, conv_features=2048, maxpool=False):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.conv_features = conv_features\n",
    "        self.n_frames = n_frames\n",
    "        self.positional_encodings = self.create_positional_encodings()\n",
    "        self.mp = maxpool\n",
    "\n",
    "        self.feature_extracter = feature_extracter\n",
    "        self.Q = nn.Linear(conv_features, hidden_size)\n",
    "        self.K = nn.Linear(conv_features, hidden_size)\n",
    "        self.V = nn.Linear(conv_features, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.scaling_factor = torch.rsqrt(torch.tensor(hidden_size, dtype=torch.float))\n",
    "        self.maxpool = nn.MaxPool1d(n_frames)\n",
    "        if self.mp:\n",
    "            self.classifier = nn.Linear(hidden_size, 1)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(hidden_size*n_frames, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        batch_size = images[0].shape[0]\n",
    "        \n",
    "        X = []\n",
    "        for x in images: # (batch, 3, 224, 224)\n",
    "            x = torch.squeeze(self.feature_extracter(x), dim=3)\n",
    "            x = torch.transpose(x, 1, 2)\n",
    "            X.append(x)\n",
    "\n",
    "        features = torch.cat(X, dim=1) # (batch, frames, 2048)\n",
    "        features = features + self.positional_encodings[:self.n_frames].unsqueeze(0)\n",
    "        q = self.Q(features)\n",
    "        k = self.K(features)\n",
    "        v = self.V(features)    \n",
    "        unnormalized_attention = torch.bmm(k, q.transpose(2,1)) * self.scaling_factor\n",
    "        attention_weights = self.softmax(unnormalized_attention)\n",
    "        if self.mp:\n",
    "            context = torch.bmm(attention_weights.transpose(2,1), v)\n",
    "            context = self.maxpool(context.transpose(1,2)).view(batch_size, -1)\n",
    "        else:\n",
    "            context = torch.bmm(attention_weights.transpose(2,1), v).view(batch_size, -1) # (batch, hidden*frames)\n",
    "        x = self.sigmoid(self.classifier(context))\n",
    "        return x\n",
    "\n",
    "    def create_positional_encodings(self, max_seq_len=100):\n",
    "      pos_indices = torch.arange(max_seq_len)[..., None]\n",
    "      dim_indices = torch.arange(self.conv_features//2)[None, ...]\n",
    "      exponents = (2*dim_indices).float()/(self.conv_features)\n",
    "      trig_args = pos_indices / (10000**exponents)\n",
    "      sin_terms = torch.sin(trig_args)\n",
    "      cos_terms = torch.cos(trig_args)\n",
    "\n",
    "      pos_encodings = torch.zeros((max_seq_len, self.conv_features))\n",
    "      pos_encodings[:, 0::2] = sin_terms\n",
    "      pos_encodings[:, 1::2] = cos_terms\n",
    "\n",
    "      pos_encodings = pos_encodings.cuda()\n",
    "\n",
    "      return pos_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9H2NEvsijJ7u"
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "model = Attention(conv_model, n_frames=n_frames, hidden_size=100, maxpool=True)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "finetune = FineTune(model, 'attention', epoch=35, optimizer=optimizer, filename='attention_100_0.0001SGD', log_interval=100)\n",
    "finetune.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "rOSaRwjCRqRk",
    "outputId": "c0613cf6-131d-4d0c-ac74-9174ac4ccc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3836 (2%)]\tLoss: 0.690529\n",
      "Train set: Average loss: 0.6897, Accuracy: 2154/3836 (56%)\n",
      "Val set: Average loss: 0.6928, Accuracy: 131/261 (50%), Precision: 0.5389, Recall: 0.7172, F1: 0.6154\n",
      "Train Epoch: 1 [0/3836 (2%)]\tLoss: 0.689202\n",
      "Train set: Average loss: 0.6870, Accuracy: 2302/3836 (60%)\n",
      "Val set: Average loss: 0.6919, Accuracy: 131/261 (50%), Precision: 0.5424, Recall: 0.6621, F1: 0.5963\n",
      "Train Epoch: 2 [0/3836 (2%)]\tLoss: 0.687627\n",
      "Train set: Average loss: 0.6830, Accuracy: 2054/3836 (54%)\n",
      "Val set: Average loss: 0.6860, Accuracy: 145/261 (56%), Precision: 0.5556, Recall: 1.0000, F1: 0.7143\n",
      "Train Epoch: 3 [0/3836 (2%)]\tLoss: 0.686445\n",
      "Train set: Average loss: 0.6828, Accuracy: 2054/3836 (54%)\n",
      "Val set: Average loss: 0.6854, Accuracy: 145/261 (56%), Precision: 0.5556, Recall: 1.0000, F1: 0.7143\n",
      "Train Epoch: 4 [0/3836 (2%)]\tLoss: 0.673925\n",
      "Train set: Average loss: 0.6779, Accuracy: 2089/3836 (54%)\n",
      "Val set: Average loss: 0.6834, Accuracy: 145/261 (56%), Precision: 0.5556, Recall: 1.0000, F1: 0.7143\n",
      "Train Epoch: 5 [0/3836 (2%)]\tLoss: 0.666696\n",
      "Train set: Average loss: 0.6747, Accuracy: 2115/3836 (55%)\n",
      "Val set: Average loss: 0.6816, Accuracy: 145/261 (56%), Precision: 0.5556, Recall: 1.0000, F1: 0.7143\n",
      "Train Epoch: 6 [0/3836 (2%)]\tLoss: 0.656582\n"
     ]
    }
   ],
   "source": [
    "# del model\n",
    "model = Attention(conv_model, n_frames=n_frames, hidden_size=100, maxpool=False)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "finetune = FineTune(model, 'attention', epoch=35, optimizer=optimizer, filename='attention_100_0.0001SGD_nomaxpool', log_interval=100)\n",
    "finetune.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8N6JXj9SIRq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjPqArmTudAN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "RNN_2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001ccf84694a47d88acda0feb1c060d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ce470e7dccb45358b6d8c580abf1cc5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25cbdbd67bc24f75a09dfa5cb7cc1c73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fa2428671d146b09f55a3327bd72f4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ce470e7dccb45358b6d8c580abf1cc5",
      "placeholder": "​",
      "style": "IPY_MODEL_cda31c347de54dac9db23b81329450a1",
      "value": " 97.8M/97.8M [00:02&lt;00:00, 35.9MB/s]"
     }
    },
    "914bc8e04c334997b9d4e47198d52836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b4c321fec74d449ba19c47a8494ab310": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25cbdbd67bc24f75a09dfa5cb7cc1c73",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_914bc8e04c334997b9d4e47198d52836",
      "value": 102502400
     }
    },
    "cda31c347de54dac9db23b81329450a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2cf26fe0d5e4a49840c2a2e5e96d8c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4c321fec74d449ba19c47a8494ab310",
       "IPY_MODEL_5fa2428671d146b09f55a3327bd72f4a"
      ],
      "layout": "IPY_MODEL_001ccf84694a47d88acda0feb1c060d5"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
